---
title: "Advanced Usage"
description: "Advanced patterns and examples for using React Audio Recorder Hook"
sidebar_position: 3
---

# Advanced Usage

This guide covers more advanced usage patterns for the React Audio Recorder Hook.

## Audio Visualization

One powerful feature you might want to add is audio waveform visualization. Here's an example of how to implement a simple audio visualizer using the hook:

```tsx
import React, { useRef, useEffect } from "react";
import useAudioRecorder from "react-audio-recorder-hook";

interface AudioRecorderWithVisualizationProps {
  width?: number;
  height?: number;
  backgroundColor?: string;
  barColor?: string;
}

function AudioRecorderWithVisualization({
  width = 500,
  height = 100,
  backgroundColor = "#f0f0f0",
  barColor = "#3a86ff",
}: AudioRecorderWithVisualizationProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const animationRef = useRef<number | null>(null);

  const {
    startRecording,
    stopRecording,
    cancelRecording,
    pauseRecording,
    resumeRecording,
    playRecording,
    saveRecording,
    isRecording,
    isPaused,
    recordingDuration,
    mediaStream,
  } = useAudioRecorder();

  useEffect(() => {
    if (!isRecording || isPaused || !mediaStream || !canvasRef.current) {
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
        animationRef.current = null;
      }
      return;
    }

    const audioContext = new (window.AudioContext ||
      (window as any).webkitAudioContext)();
    const analyser = audioContext.createAnalyser();
    const source = audioContext.createMediaStreamSource(mediaStream);

    analyser.fftSize = 256;
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    source.connect(analyser);

    const canvas = canvasRef.current;
    const canvasCtx = canvas.getContext("2d");

    const draw = () => {
      analyser.getByteFrequencyData(dataArray);

      canvasCtx.fillStyle = backgroundColor;
      canvasCtx.fillRect(0, 0, width, height);

      const barWidth = (width / bufferLength) * 2.5;
      let x = 0;

      for (let i = 0; i < bufferLength; i++) {
        const barHeight = (dataArray[i] / 255) * height;

        canvasCtx.fillStyle = barColor;
        canvasCtx.fillRect(x, height - barHeight, barWidth, barHeight);

        x += barWidth + 1;
      }

      animationRef.current = requestAnimationFrame(draw);
    };

    draw();

    return () => {
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }
      source.disconnect();
      audioContext.close();
    };
  }, [
    isRecording,
    isPaused,
    mediaStream,
    backgroundColor,
    barColor,
    height,
    width,
  ]);

  const handleSave = async () => {
    const recording = await saveRecording();
    if (recording) {
      console.log("Recording saved:", recording.blob);
    }
  };

  return (
    <div>
      <canvas
        ref={canvasRef}
        width={width}
        height={height}
        style={{ border: "1px solid #ddd", borderRadius: "4px" }}
      />

      <div style={{ marginTop: "1rem" }}>
        <div>
          Recording: {isRecording ? "Yes" : "No"} {isPaused && "(Paused)"}
        </div>
        <div>Duration: {recordingDuration}s</div>

        <div style={{ marginTop: "0.5rem", display: "flex", gap: "0.5rem" }}>
          {!isRecording && (
            <button onClick={startRecording}>Start Recording</button>
          )}

          {isRecording && !isPaused && (
            <button onClick={pauseRecording}>Pause</button>
          )}

          {isRecording && isPaused && (
            <button onClick={resumeRecording}>Resume</button>
          )}

          {isRecording && <button onClick={stopRecording}>Stop</button>}

          {isRecording && <button onClick={cancelRecording}>Cancel</button>}

          <button onClick={handleSave}>Save</button>
        </div>
      </div>
    </div>
  );
}
```

## Custom Audio Processing

You can extend the hook's functionality by adding custom audio processing before saving the recording:

```tsx
import { useState } from "react";
import useAudioRecorder from "react-audio-recorder-hook";

function AudioRecorderWithProcessing() {
  const [gain, setGain] = useState(1);
  const recorder = useAudioRecorder();

  const processAndSaveAudio = async () => {
    const recording = await recorder.saveRecording();
    if (!recording) return null;

    // Process the audio using Web Audio API
    const audioContext = new (window.AudioContext ||
      (window as any).webkitAudioContext)();
    const arrayBuffer = await recording.blob.arrayBuffer();
    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

    // Create a new buffer with the same properties
    const processedBuffer = audioContext.createBuffer(
      audioBuffer.numberOfChannels,
      audioBuffer.length,
      audioBuffer.sampleRate
    );

    // Apply gain
    for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
      const inputData = audioBuffer.getChannelData(channel);
      const outputData = processedBuffer.getChannelData(channel);

      for (let i = 0; i < inputData.length; i++) {
        // Apply gain (be careful with clipping)
        outputData[i] = Math.max(-1, Math.min(1, inputData[i] * gain));
      }
    }

    // Convert back to blob
    const offlineContext = new OfflineAudioContext(
      processedBuffer.numberOfChannels,
      processedBuffer.length,
      processedBuffer.sampleRate
    );

    const source = offlineContext.createBufferSource();
    source.buffer = processedBuffer;
    source.connect(offlineContext.destination);
    source.start();

    const renderedBuffer = await offlineContext.startRendering();

    // Convert AudioBuffer to WAV Blob
    const wavBlob = bufferToWav(renderedBuffer);
    const url = URL.createObjectURL(wavBlob);

    return { blob: wavBlob, url };
  };

  // This is a simplified WAV encoder function
  const bufferToWav = (buffer) => {
    // Implementation details omitted for brevity
    // In a real application, you would use a library or implement a WAV encoder
    return new Blob(["dummy data"], { type: "audio/wav" });
  };

  return (
    <div>
      {/* UI controls */}
      <div>
        <label>
          Gain:
          <input
            type="range"
            min="0"
            max="2"
            step="0.1"
            value={gain}
            onChange={(e) => setGain(parseFloat(e.target.value))}
          />
          {gain.toFixed(1)}
        </label>
      </div>

      {/* Recording controls */}
      {/* ... Similar to basic example ... */}

      <button onClick={processAndSaveAudio}>Process and Save</button>
    </div>
  );
}
```

## Uploading to a Server

Here's an example of how to upload a recording to a server:

```tsx
import { useState } from "react";
import useAudioRecorder from "react-audio-recorder-hook";

function AudioRecorderWithUpload() {
  const [isUploading, setIsUploading] = useState(false);
  const [uploadProgress, setUploadProgress] = useState(0);
  const recorder = useAudioRecorder();

  const uploadRecording = async () => {
    const recording = await recorder.saveRecording();
    if (!recording) return;

    setIsUploading(true);
    setUploadProgress(0);

    const formData = new FormData();
    formData.append("audio", recording.blob, "recording.webm");

    try {
      const xhr = new XMLHttpRequest();

      xhr.upload.addEventListener("progress", (event) => {
        if (event.lengthComputable) {
          const progress = Math.round((event.loaded / event.total) * 100);
          setUploadProgress(progress);
        }
      });

      xhr.addEventListener("load", () => {
        if (xhr.status >= 200 && xhr.status < 300) {
          alert("Upload successful!");
        } else {
          throw new Error(`HTTP error ${xhr.status}`);
        }
        setIsUploading(false);
      });

      xhr.addEventListener("error", () => {
        alert("Upload failed");
        setIsUploading(false);
      });

      xhr.open("POST", "/api/upload-audio");
      xhr.send(formData);
    } catch (error) {
      console.error("Upload error:", error);
      setIsUploading(false);
    }
  };

  return (
    <div>
      {/* Recording controls */}
      {/* ... Similar to basic example ... */}

      <button
        onClick={uploadRecording}
        disabled={isUploading || !recorder.recordingDuration}
      >
        {isUploading ? "Uploading..." : "Upload Recording"}
      </button>

      {isUploading && (
        <div>
          <progress value={uploadProgress} max="100" />
          <span>{uploadProgress}%</span>
        </div>
      )}
    </div>
  );
}
```

## Using with React Context

For larger applications, you might want to provide the audio recorder functionality through React Context:

```tsx
import React, { createContext, useContext, ReactNode } from "react";
import useAudioRecorder from "react-audio-recorder-hook";

// Create the context with a default undefined value
const AudioRecorderContext = createContext<
  ReturnType<typeof useAudioRecorder> | undefined
>(undefined);

interface AudioRecorderProviderProps {
  children: ReactNode;
  audioConstraints?: MediaTrackConstraints;
  chunkInterval?: number;
  preferredMimeType?: string;
}

export function AudioRecorderProvider({
  children,
  audioConstraints,
  chunkInterval,
  preferredMimeType,
}: AudioRecorderProviderProps) {
  const recorder = useAudioRecorder({
    audioConstraints,
    chunkInterval,
    preferredMimeType,
  });

  return (
    <AudioRecorderContext.Provider value={recorder}>
      {children}
    </AudioRecorderContext.Provider>
  );
}

// Custom hook to use the audio recorder context
export function useAudioRecorderContext() {
  const context = useContext(AudioRecorderContext);

  if (context === undefined) {
    throw new Error(
      "useAudioRecorderContext must be used within an AudioRecorderProvider"
    );
  }

  return context;
}

// Usage example:
function App() {
  return (
    <AudioRecorderProvider audioConstraints={{ echoCancellation: true }}>
      <RecordButton />
      <RecordingStatus />
      <PlaybackControls />
    </AudioRecorderProvider>
  );
}

function RecordButton() {
  const { isRecording, startRecording, stopRecording } =
    useAudioRecorderContext();

  return (
    <button onClick={isRecording ? stopRecording : startRecording}>
      {isRecording ? "Stop" : "Record"}
    </button>
  );
}
```
